
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
  0% 0/128 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/zinzinbin/codes_for_study/gnn/MNIST_GNN/train_dynamic_reduction_network.py", line 73, in <module>
    train_loss, train_acc, valid_loss, valid_acc = train_wandb(model, train_loader, criterion, optimizer, scheduler, device, num_epochs, is_valid=True, valid_loader=valid_loader, verbose = True, verbose_period=1, save_best_only=True, save_path=save_path, max_grad_norm=max_grad_norm)
  File "/home/zinzinbin/codes_for_study/gnn/MNIST_GNN/utility/train.py", line 258, in train_wandb
    train_loss, train_acc = train_per_epoch(
  File "/home/zinzinbin/codes_for_study/gnn/MNIST_GNN/utility/train.py", line 19, in train_per_epoch
    pred = model.forward(batch)
  File "/home/zinzinbin/codes_for_study/gnn/MNIST_GNN/model/network.py", line 314, in forward
    x = self.edgeconv1(x, edge_idx)
  File "/home/zinzinbin/.conda/envs/gnn_environment/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zinzinbin/.conda/envs/gnn_environment/lib/python3.9/site-packages/torch_geometric/nn/conv/edge_conv.py", line 51, in forward
    return self.propagate(edge_index, x=x, size=None)
  File "/home/zinzinbin/.conda/envs/gnn_environment/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py", line 309, in propagate
    out = self.message(**msg_kwargs)
  File "/home/zinzinbin/.conda/envs/gnn_environment/lib/python3.9/site-packages/torch_geometric/nn/conv/edge_conv.py", line 54, in message
    return self.nn(torch.cat([x_i, x_j - x_i], dim=-1))
RuntimeError: CUDA out of memory. Tried to allocate 272.00 MiB (GPU 1; 11.91 GiB total capacity; 546.70 MiB already allocated; 8.94 MiB free; 582.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF